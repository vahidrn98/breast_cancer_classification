{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('ggplot')\n",
    "\n",
    "class svm:\n",
    "    def __init__(self,visualize=False):\n",
    "        self.visualize=visualize\n",
    "        self.colors = {-1:'r',1:'b'}\n",
    "        if self.visualize:\n",
    "            self.fig = plt.figure()\n",
    "            self.axis = self.fig.add_subplot(1,1,1)\n",
    "    def train(self,data):\n",
    "            self.data = data\n",
    "            #keeping w and b amount in every opoch: opt_dict = {|w| :[w,b]}\n",
    "            opt_dic = {}\n",
    "            #transforms for creating different w with the same |w|(because we gotta check all of them !)\n",
    "            transforms = [[1,1],[-1,1],[-1,-1],[1,-1]]\n",
    "            #saving w and b values for stepping\n",
    "            all_data = []\n",
    "            for yi in self.data:\n",
    "                for featureset in self.data[yi]:\n",
    "                    for feature in featureset:\n",
    "                        all_data.append(feature)\n",
    "            self.max = max(all_data)\n",
    "            self.min = min(all_data)\n",
    "            #freeing the all_data from memory\n",
    "            all_data = None\n",
    "            step_sizes = [self.max*0.1,self.max*0.01,self.max*0.001]\n",
    "            #b step sizes\n",
    "            b_range_step = 5\n",
    "            b_step = 5\n",
    "            latest_optimum = self.max * 10 #starting definition of vector w\n",
    "            for step in step_sizes:\n",
    "                w = np.array([latest_optimum,latest_optimum])\n",
    "                optimized = False\n",
    "                while not optimized:\n",
    "                    for b in np.arange(-1*self.max*b_range_step,self.max*b_range_step,step*b_step):#third value: step size for arange\n",
    "                        for transformation in transforms:\n",
    "                            w_transformed = w*transformation\n",
    "                            found_option = True\n",
    "                            for yi in self.data:\n",
    "                                for xi in self.data[yi]:\n",
    "                                    if not yi*(np.dot(xi,w_transformed)+b)>=1:\n",
    "                                        found_option = False\n",
    "                                        break # not nesessary to check others since we already got the wrong w and b\n",
    "                            if found_option:\n",
    "                                opt_dic[np.linalg.norm(w_transformed)] = [w_transformed,b]\n",
    "                    if(w[0]<0):\n",
    "                        optimized = True\n",
    "                        print('optimized a step')\n",
    "                    else:\n",
    "                        w = w-step\n",
    "                norms = sorted([n for n in opt_dic])\n",
    "                #opt_dict : |w|: [w,b]\n",
    "                opt_choice = opt_dic[norms[0]]\n",
    "                self.w = opt_choice[0]\n",
    "                self.b = opt_choice[1]\n",
    "                print(opt_choice)\n",
    "                latest_optimum = opt_choice[0][0] + step *2\n",
    "            for i in self.data:\n",
    "                for xi in self.data[i]:\n",
    "                    yi=i\n",
    "                    print(xi,':',yi*(np.dot(self.w,xi)+self.b))\n",
    "    def predict(self,features):\n",
    "            clf = np.sign(np.dot(np.array(features),np.array(self.w))+self.b)\n",
    "            if clf !=0 and self.visualize:\n",
    "                self.axis.scatter(features[0],features[1],s=200,marker='*',c=self.colors[clf])\n",
    "            return clf\n",
    "    def plot_svm(self):\n",
    "        #scattering known featuresets.\n",
    "        [[self.axis.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data[i]] for i in data]\n",
    "        def hyperplane(x,w,b,v):\n",
    "            # v = (w.x+b)\n",
    "            return (-w[0]*x-b+v) / w[1]\n",
    "        datarange = (self.min*0.9,self.max*1.1)\n",
    "        hyp_x_min = datarange[0]\n",
    "        hyp_x_max = datarange[1]\n",
    "        # w.x + b = 1\n",
    "        # pos sv hyperplane\n",
    "        psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\n",
    "        psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\n",
    "        self.axis.plot([hyp_x_min,hyp_x_max], [psv1,psv2], \"k\")\n",
    "        # w.x + b = -1\n",
    "        # negative sv hyperplane\n",
    "        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\n",
    "        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\n",
    "        self.axis.plot([hyp_x_min,hyp_x_max], [nsv1,nsv2], \"k\")\n",
    "\n",
    "        # w.x + b = 0\n",
    "        # decision\n",
    "        db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\n",
    "        db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\n",
    "        self.axis.plot([hyp_x_min,hyp_x_max], [db1,db2], \"g--\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mysvm = svm(visualize=True)\n",
    "data = {-1:[[1,3],[2,4],[3,5]],1:[[5,7],[6,8],[7,9]]}\n",
    "xs = []\n",
    "ys = []\n",
    "color = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized a step\n",
      "[array([1.8, 0.9]), -13.5]\n",
      "optimized a step\n",
      "[array([0.63, 0.54]), -5.849999999999753]\n",
      "optimized a step\n",
      "[array([0.513, 0.504]), -5.084999999998487]\n",
      "[1, 3] : 3.0599999999988277\n",
      "[2, 4] : 2.0429999999989974\n",
      "[3, 5] : 1.0259999999991676\n",
      "[5, 7] : 1.008000000000492\n",
      "[6, 8] : 2.025000000000322\n",
      "[7, 9] : 3.0420000000001526\n"
     ]
    }
   ],
   "source": [
    "mysvm.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysvm.plot_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, -1.0, -1.0]\n"
     ]
    }
   ],
   "source": [
    "pred = [[0,10],[1,3],[3,4]]\n",
    "res = []\n",
    "for p in pred:\n",
    "    res.append(mysvm.predict(p))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysvm.plot_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
